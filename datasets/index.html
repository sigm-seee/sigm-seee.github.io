<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Datasets</title>
  <meta name="description" content="Datasets in the lab">
  <meta name="author" content="Kyle E. Niemeyer">

  <!-- Enable responsive viewport -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Bootstrap styles -->
  <link href="/assets/themes/lab/bootstrap/css/bootstrap.min.css" rel="stylesheet" />

  <!-- Sticky Footer -->
  <link href="/assets/themes/lab/bootstrap/css/bs-sticky-footer.css" rel="stylesheet" />

  <!-- Custom styles -->
  <link href="/assets/themes/lab/css/style.css?body=1" rel="stylesheet" type="text/css" media="all" />

  <!-- icon -->
  <!-- <link rel="apple-touch-icon" sizes="180x180" href="/assets/themes/lab/images/logo/apple-touch-icon.png">
    <link rel="icon" type="image/png" href="/assets/themes/lab/images/logo/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/assets/themes/lab/images/logo/favicon-16x16.png" sizes="16x16"> -->
  <link rel="manifest" href="/assets/themes/lab/images/logo/icon-lab.jpg">
  <link rel="mask-icon" href="/assets/themes/lab/images/logo/icon-lab.jpg" color="#5bbad5">
  <!-- <link rel="shortcut icon" href="/assets/themes/lab/images/logo/icon32x32.png"> -->
  <link rel="shortcut icon" href="/assets/themes/lab/images/logo/icon-lab.jpg">
  <meta name="msapplication-config" content="/assets/themes/lab/images/logo/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">

  <!-- Custom fonts and icons via Font Awesome, http://fortawesome.github.io/Font-Awesome/ -->
  <!--<script src="https://use.fontawesome.com/51d391e302.js"></script> -->
  <script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>

  <!-- Academicons: https://jpswalsh.github.io/academicons/ -->
  <link rel="stylesheet" href="/assets/css/academicons.min.css" />

  <link rel="stylesheet" href="/assets/css/icon-list-group.css" />

  <!-- Fonts via Google -->
  <link href='https://fonts.googleapis.com/css?family=Lato:300italic,700italic,300,700' rel='stylesheet'
    type='text/css' />

  <!-- Math via MathJax -->
  <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

  <!-- atom & rss feed
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    -->

</head>

<body>

  <!-- Static top navbar -->
  <iframe src="/includes/menu_top.html"
    onload="this.before((this.contentDocument.body||this.contentDocument).children[0]);this.remove()"> </iframe>

  <!-- Content -->
  <div class="container">
    <h2>Datasets</h2>
    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/ForestSeg/Tree.png" alt="Forest Tree Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/ForestSeg.html" target="_blank">
            <h4 class="media-heading">Forest Segmentation Dataset <small class="text-muted">(2025)</small></h4>
          </a>


          <p style="text-align: justify;">
            ForestSeg-T1 contains 1,832 high-resolution UAV images from Vietnam National University of Forestry in
            Hanoi, captured using DJI Phantom 4 RTK and DJI Air 3 at 70–211m altitudes. Each image includes 1–17
            manually annotated tree crowns and flight parameters. The dataset supports forest monitoring, biomass
            estimation, and environmental change detection. Its multi-seasonal imagery enables long-term forest
            analysis. Evaluations across four time intervals (T1–T4) show that environmental conditions impact
            segmentation performance, with T4 achieving the best results (AP 60.82%, accuracy 71.32%), emphasizing the
            importance of temporal diversity and data quality.
          </p>
        </div>
      </div>
    </div>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/OvarianTumor/OvaTUS.png"
              alt="OvaTUS Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/Ovarian.html" target="_blank">
            <h4 class="media-heading">Ovarian Tumor Dataset (OvaTUS) <small class="text-muted">(2025)</small></h4>
          </a>


          <p style="text-align: justify;">
            The OvaTUS dataset was collected by our research team in collaboration with the National Hospital of
            Obstetrics and Gynecology (NHOG) in Hanoi, Vietnam. It includes ultrasound images from women who visited the
            hospital for ovarian tumor assessments and consented to participate in the study. The dataset contains six
            labeled categories: Unilocular Cyst, Solid Tumor, Hemorrhagic Tumor, Multilocular Cyst, Solid Multilocular
            Cyst, and Solid Unilocular Cyst. The dataset has been thoroughly annotated with accurate labels by experts
            and sonographer, and the
            process of data collection is still ongoing.
          </p>
        </div>
      </div>
    </div>

    <hr>
    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="pull-right" href="#" class="text-center">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/CoboGesture/s7_TranVanThang_2_35_38.gif"
              alt="The CStudentAct Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/CoboGesture.html">
            <h4 class="media-heading">The CoboGesture Dataset <small class="text-muted">(2024)</small></h4>
          </a>
          <p style="text-align: justify;">The dataset consists of 150 videos from 50 subjects, including 11 females and
            39 males.
            Each video ranges from 100 seconds to 140 seconds in length and contains 2,479 gesture samples divided into
            19 classes.
            The time interval between two gestures is approximately 4 seconds.
            In total, these 150 videos result in 490,000 RGB frames, corresponding to about 4.5 hours of video.
          </p>

        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="pull-right" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/CStudentAct/CStudentAct.jpg"
              alt="The CStudentAct Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/CStudentAct.html">
            <h4 class="media-heading">The CStudentAct Dataset <small class="text-muted">(2024)</small></h4>
          </a>
          <p style="text-align: justify;">Although several image and video datasets have been collected for student
            activity recognition,
            they are mainly annotated at the frame level or sequence level, which can be used for object detection-based
            and video classification-based approaches.
            Therefore, to promote research in continuous student activity recognition, we have prepared a new dataset
            named CStudentAct.
            The CStudentAct Dataset is an extension of the StudentAct Dataset</p>

        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="pull-right" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/VietForest/VietForest.png"
              alt="The VietForest dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/VietForest.html">
            <h4 class="media-heading">The VietForest dataset <small class="text-muted">(2024)</small></h4>
          </a>
          <p style="text-align: justify;">Our Vietnamese forestry dataset (VietForest) is a valuable
            resource comprising 156 classes of plant species predominantly found in the forests of Phu Tho province.
            This dataset
            encompasses a diverse range of flora, including 18 orders, 45
            families, and 122 genera, totaling 26,251 images. The dataset
            showcases local plant species, many of which hold significant
            ecological importance and some of which are listed for conservation efforts. The dataset not only aids in
            understanding the
            local habitat but also provides detailed biological information
            associated with each species</p>

        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="pull-right" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/VnBeeTracking/annotation.png"
              alt="The Pollenbee Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/VnBeeTracking.html">
            <h4 class="media-heading">The VnBeeTracking Dataset <small class="text-muted">(2023)</small></h4>
          </a>
          <p style="text-align: justify;">The VnBeeTracking Dataset is built for the purpose of serving the tracking
            honeybee problem.</p>
          <p style="text-align: justify;">The videos in the dataset are collected at the beehive entrance at the
            Research Center for Tropical Bees
            and Beekeeping, Vietnam National University of Agriculture in April 2022. </p>
          <p style="text-align: justify;">We used a data acquisition system consisting of an Nvidia jetson nano
            development kit and an IMX477 HQ
            camera with a 6mm CS-Mount lens
            which are placed in a housing surveillance weatherproof outdoor camera box. </p>

        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="https://dinhtus49.github.io/">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/pollenbee/video_dataset.gif"
              alt="The Pollenbee Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/pollenbee.html">
            <h4 class="media-heading">The VnPollenBee Dataset <small class="text-muted">(2022)</small></h4>
          </a>


          <p style="text-align: justify;">
            The VnPollenbee Dataset is built for the purpose of serving the problem of detecting pollen bees.
            The dataset contains more than 2000 imagesconsisting of 1,758 pollen bearing and 59,068 non-pollen bearing
            bees. <br>
            The dataset was collected at the bee farm of the Vietnam Agricultural Academy by a data acquisition system
            consisting of an
            Nvidia jetson nano development kit and an IMX477 HQ camera with a 6mm CS-Mount lens,
            all devices are placed in a housing surveillance weatherproof outdoor camera box. We adjust the camera along
            with the downward-facing view.
            We attach the housing surveillance weatherproof outdoor camera box within only one stage of the hive body.
            Our data acquisition system:
          </p>
        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/StudentAct/CameraSetting.png"
              alt="StudentAct Dataset">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/StudentAct.html" target="_blank">
            <h4 class="media-heading">StudentAct Dataset <small class="text-muted">(2021)</small></h4>
          </a>


          <p style="text-align: justify;">
            The StudentAct dataset is meant to aid research efforts in the general area of developing, testing and
            evaluating algorithms for
            human activity recognition. The Hanoi University of Science and Technology (HUST) has copyright in the
            collection of
            activity video and associated data and serves as a distributor of the StudentAct dataset.
          </p>
        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="#">
            <img class="pull-left mr-3 img-fluid"
              src="/assets/images/datasets/VnPersonSearch3000/VnPersonSearch3000.jpg" alt="Fully Automated Person ReID">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/VnPersonSearch3000.html" target="_blank">
            <h4 class="media-heading">VnPersonSearch3000 <small class="text-muted">(2021)</small></h4>
          </a>


          <p style="text-align: justify;">
            The 3000VnPersonSearch dataset includes pairs of image and description. The images are
            person bounding boxes that are extracted from video frames. The videos are captured by
            both moving cameras and fixed-position cameras with different fields of view. They are
            captured during day and night time with street lamp light. The capture scenarios are mostly
            crowded street and outdoor festival scenes, so the occlusion and pose variance also appear
          </p>
        </div>
      </div>
    </div>

    <hr>

    <div class='row'>
      <div class="media mb-1 mt-1">
        <div class="col-md-4">
          <a class="media-left" href="#">
            <img class="pull-left mr-3 img-fluid" src="/assets/images/datasets/FAPR.jpg"
              alt="Fully Automated Person ReID">
          </a>
        </div>
        <div class="media-body col-md-8">
          <!-- <a href="pollenbee.html"> -->
          <a href="/datasets/FAPR.html" target="_blank">
            <h4 class="media-heading">Fully Automated Person ReID (FAPR) <small class="text-muted">(2020)</small></h4>
          </a>
          <!-- Member list here -->
          <!-- <a href="#">
                  <img src="/assets/images/team/le-thi-lan-300x300.jpg" class="img-circle" alt="Thi-Lan Le" height="60">
                </a>

                <a href="#">
                  <img src="/assets/images/team/Hong-QuanNguyen.jpg" class="img-circle" alt="Hong-Quan Nguyen" height="60">
                </a>
                                
                <a href="#">
                  <img src="/assets/images/team/Thuy-BinhNguyen.jpg" class="img-circle" alt="Thuy-Binh Nguyen" height="60">
                </a>                           -->

          <p style="text-align: justify;">
            This dataset contains total 15 videos and is recorded on three days by two static non-overlapping cameras
            with HD resolution (1920 × 1080),
            at 20 frames per second (fps) in indoor and outdoor environment conditions. There are 7 to 10 different
            people in each video.
            The result of splitting the frames is 11876 images that have been labeled with the boundingboxes and
            corresponding identifiers.
            There are 28567 boundingbox. Dataset can be used for human detection, tracking, and re-identification
            problems
          </p>
        </div>
      </div>
    </div>


  </div>

  <!-- Static bottom navbar -->
  <iframe src="/includes/footer.html"
    onload="this.before((this.contentDocument.body||this.contentDocument).children[0]);this.remove()"> </iframe>


  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script src="/assets/themes/lab/bootstrap/js/bootstrap.min.js"></script>

</body>

</html>