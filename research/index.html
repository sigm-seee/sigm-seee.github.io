
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Research</title>
    <meta name="description" content="Research projects in the lab">
    <meta name="author" content="Kyle E. Niemeyer">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>

    <!-- Bootstrap styles -->
    <link href="/assets/themes/lab/bootstrap/css/bootstrap.min.css" rel="stylesheet"/>
    
    <!-- Sticky Footer -->
    <link href="/assets/themes/lab/bootstrap/css/bs-sticky-footer.css" rel="stylesheet"/>

    <!-- Custom styles -->
    <link href="/assets/themes/lab/css/style.css?body=1" rel="stylesheet" type="text/css" media="all"/>

    <!-- icon -->
    <!-- <link rel="apple-touch-icon" sizes="180x180" href="/assets/themes/lab/images/logo/apple-touch-icon.png"> -->
    <!-- <link rel="icon" type="image/png" href="/assets/themes/lab/images/logo/favicon-32x32.png" sizes="32x32"> -->
    <!-- <link rel="icon" type="image/png" href="/assets/themes/lab/images/logo/favicon-16x16.png" sizes="16x16"> -->
    <link rel="manifest" href="/assets/themes/lab/images/logo/manifest.json">
    <link rel="mask-icon" href="/assets/themes/lab/images/logo/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="/assets/themes/lab/images/logo/icon32x32.png">
    <meta name="msapplication-config" content="/assets/themes/lab/images/logo/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">

    <!-- Custom fonts and icons via Font Awesome, http://fortawesome.github.io/Font-Awesome/ -->
    <!--<script src="https://use.fontawesome.com/51d391e302.js"></script> -->
    <script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>

    <!-- Academicons: https://jpswalsh.github.io/academicons/ -->
    <link rel="stylesheet" href="/assets/css/academicons.min.css"/>

    <link rel="stylesheet" href="/assets/css/icon-list-group.css"/>

    <!-- Fonts via Google -->
    <link href='https://fonts.googleapis.com/css?family=Lato:300italic,700italic,300,700' rel='stylesheet' type='text/css'/>

    <!-- Math via MathJax -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <!-- atom & rss feed
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    -->
    <style>
      div {
        text-align: justify;
        text-justify: inter-word;
      }
    </style>

  </head>

  <body>
    <!-- Static top navbar -->
    <iframe src="/includes/menu_top.html" onload="this.before((this.contentDocument.body||this.contentDocument).children[0]);this.remove()"> </iframe>  
  
    <!-- Content -->
    <div class="container">
    <h2>Active Projects</h2>
    <!-- <div class="container"> -->

      <div class='row'>
          <div class="media mb-1 mt-1">
              <div class="col-md-4">
              <a class="media-left" href="#">                
                <img class="pull-left mr-3 img-fluid" src="/assets/images/researches/person_reid/fw.jpg" alt="ANOMOLY DETECTION">
                <img class="pull-left mr-3 img-fluid" src="/assets/images/researches/person_reid/fusion.jpg" alt="ANOMOLY DETECTION">
              </a>
              </div>
              <div class="media-body col-md-8">
                  <a href="#">
                  <h4 class="media-heading">PERSON RE-IDENTIFICATION<small class="text-muted">(2015–)</small></h4>
                  </a>
                  
                  <a href="#">
                    <img src="/assets/images/team/le-thi-lan-300x300.jpg" class="img-circle" alt="Thi-Lan Le" height="60">
                  </a>

                  <a href="#">
                    <img src="/assets/images/team/Thuy-BinhNguyen.jpg" class="img-circle" alt="Thuy-Binh Nguyen" height="60">
                  </a>
                  
                  <a href="#">
                    <img src="/assets/images/team/Hong-QuanNguyen.png" class="img-circle" alt="Hong-Quan Nguyen" height="60">
                  </a>
                                 
                  <p>Person Re-ID is defined as a matching problem of multiple instances of a person captured by different cameras (i.e. different
                    views). Depending on the number of images used for person representation, person ReID
                    methods can be categorized into two approaches: single-shot (in which one sole image is
                    used) and multi-shot ones (in which a sequence of images is used for each person). Person
                    Re-ID is non-trivial problem due to different challenges such as strong variations in illumi-
                    nations, poses, view-points and visual appearance; occlusion happened in crowded scenes.
                    In order to overcome these challenges, many great efforts have been made to build robust
                    descriptors for person representation [3], to propose effective distance metrics for person
                    matching or to combine different features through fusion technique</p>

                  <p><a href="https://ieeexplore.ieee.org/document/9924686/" class="off"><i class="far fa-file-alt fa-fw" aria-hidden="true"></i>Exploiting matching local information for person re-identification </a>(2022)</p>
                  <p><a href="https://www.worldscientific.com/doi/abs/10.1142/S2196888821500172" class="off"><i class="far fa-file-alt fa-fw" aria-hidden="true"></i>Robust Person Re-Identification Through the Combination of Metric Learning and Late Fusion Techniques </a>(2020)</p>
                  <!-- expand if more than 3 papers -->
                  

              </div>
          </div>
      </div>
      
      <div class='row'>
            <div class="media mb-1 mt-1">
                <div class="col-md-4">
                <a class="media-left" href="#">
                  
                  <img class="pull-left mr-3 img-fluid" src="/assets/images/researches/action_recognition/system.jpg" alt="IMAGE CAPTIONING">
                  <!-- <img class="pull-left mr-3 img-fluid" src="/assets/images/researches/action_recognition/handshake_deeph.gif" alt="IMAGE CAPTIONING">
                  <img class="pull-left mr-3 img-fluid" src="/assets/images/researches/action_recognition/handshake_skeleton.gif" alt="IMAGE CAPTIONING"> -->


                </a>
                </div>
                <div class="media-body col-md-8">
                    <a href="#">
                    <h4 class="media-heading">HUMAN ACTION AND DYNAMIC HAN GESTURES RECOGNITION<small class="text-muted">(2010–)</small></h4>
                    </a>
                    
                    <a href="#">
                      <img src="/assets/images/team/thay_hai_vu.jpg" class="img-circle" alt="hAI vU" height="60">
                    </a>                  
                    
                    <a href="#">
                      <img src="/assets/images/team/thanh-hai-300x300.jpg" class="img-circle" alt="Thanh-Hai Tran" height="60">
                    </a>        
                      

                    <p>The use of hand gestures provides an attractive alternative to
                      cumbersome interface devices in human-computer interaction (HCI). In such applications, gestures are acquired by sensors
                      then automatically recognized and matched to several commands to control the machines. In the literature, a number of
                      studies on this topic have significantly increased in recent years due to their wide applications in virtual reality,
                      game, and healthcare or HCI. To be deployed in practice, hand gestures need to be intuitively designed while still being
                      easy to memorize for users, easy to implement, and simple to deploy. Besides, the algorithms for hand gesture recognition
                      must be highly accurate and lightweight to run on low-resource computers or edge devices </p>

                    <p><a href="https://ieeexplore.ieee.org/document/10135101" class="off"><i class="far fa-file-alt fa-fw" aria-hidden="true"></i>Hand Gesture Recognition From Wrist-Worn Camera for Human–Machine Interaction</a>(2023)</p>
                    <p><a href="https://ieeexplore.ieee.org/document/9980250" class="off"><i class="far fa-file-alt fa-fw" aria-hidden="true"></i>Dynamic Hand Gesture Recognition from Egocentric Videos based on SlowFast Architecture</a>(2022)</p>
                  
                    <!-- expand if more than 3 papers -->
                    

                </div>
            </div>
      </div>
    </div>
    

   <!-- Static bottom navbar -->
   <iframe src="/includes/footer.html" onload="this.before((this.contentDocument.body||this.contentDocument).children[0]);this.remove()"> </iframe>
  
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="/assets/themes/lab/bootstrap/js/bootstrap.min.js"></script>

  </body>
</html>

